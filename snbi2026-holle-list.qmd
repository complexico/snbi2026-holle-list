---
title: "The Digitised Holle List Project: Building Database from Legacy Materials for Conserving Indigenous Indonesian Languages"
title-prefix: "Digitsed Holle List"
author: 
  - name:
      given: "Gede Primahadi Wijaya"
      family: "Rajeg"
    orcid: "0000-0002-2047-8621"
    affiliation: 
      id: unud
      name: Universitas Udayana
      country: Indonesia
date: 2026-02-03
date-modified: now
abstract: 'Advances in cloud computing, as well as computational tools for extracting text from images, offer an opportunity to scale up the development of digital databases for Indigenous languages. This paper reports on the application of these advances to the digitalisation of old, paper-borne lexical items of over a hundred Indigenous languages in Indonesia; these items are part of the so-called [Holle List (HL)](http://hdl.handle.net/1885/144430). After introducing the (structure of the) HL, the paper underlines the motivation for the [HL digitalisation project](https://portal.sds.ox.ac.uk/projects/Digitised_Holle_List/259172). It then provides an overview of *[Google Colab](https://colab.research.google.com/)* as a free cloud-computing platform for executing a series of optical character recognition (OCR) operations on hundreds of scanned pages of the HL, utilising *[pytesseract](https://pypi.org/project/pytesseract/)*, a Python interface for *[Google’s Tesseract-OCR engine](https://github.com/tesseract-ocr/tesseract)*. Advantages (e.g., computational searchability and manipulability), as well as issues (especially typos and unrecognised characters) in the plain-text OCR outputs, are discussed. In conclusion, the paper highlights the importance of digital technology in conserving Indigenous languages via digital platforms, albeit some unavoidable challenges that require humans (linguistic and manual) intervention.'
format:
    html: 
      page-layout: full
      number-sections: true
      fig-width: 6
      fig-asp: 0.618
      fig-dpi: 300
      code-fold: true
      citations-hover: true
      footnotes-hover: true
      toc: true
      toc-location: left
      crossref: 
        sec-prefix: §
editor: visual
bibliography: references.bib
csl: apa7.csl
google-scholar: true
search: true
---

## Introduction {#sec-intro}

This paper reports on a digital humanities project of digitalising and curating large volumes of word list, the so-called *Holle List vocabulary*. The Holle List project was initiated in the late 19^th^ century by [Karel Frederik Holle](https://en.wikipedia.org/wiki/Karel_Holle), a Dutch colonial administrator. His aim was to gain knowledge about the linguistic situation of the Dutch East Indies of the present-day state of Indonesia. In the first edition of the Holle List [@holle1894], K. F. Holle set up a list of elicitation concepts (i.e., 905 concepts to be exact) given in Dutch [@holle1894, 8-38]. This list was dispersed throughout the Indonesian archipelago. The goal was to collect the corresponding expressions/words of these elicited concepts (from various semantic domains) across over two hundreds indigenous regional language-varieties of Indonesia.

Between 1980 and 1987, W. A. L. Stokhof and his colleagues (viz. Lia Saleh-Bronckhorst and Alma E. Almanar) edited, collated, and published (i) the different versions of the reference/master, elicitation Holle List as well as (ii) the corresponding expressions/words in the indigenous language-varieties into eleven-volume publication series[^1]. These publications are available open access under the Creative Commons License (see @fig-holle-list-search-output in @sec-data-source-acquisition). There are two main parts of these publications. The first one is the volume containing just the reference (or master) Holle List [@holleli1980], comprising the elicitation concepts given in Dutch, English, and Indonesian/Malay together with the index numbers of these concepts (see @fig-matching-master-and-regional-1); this is called *The New Basic List* (hereafter NBL) in Stokhof [-@holleli1980] because Stokhof and colleagues collated three different versions of the Holle List (namely those published in 1894, 1904/1911, and 1931; see @fig-matching-master-and-regional-1). The second part of the Holle List publications is the separate volumes containing the expressions/words of the regional language-varieties and their index numbers (see @fig-matching-master-and-regional-2 for an example from the Enggano language \[Glottocode: [engg1245](http://glottolog.org/resource/languoid/id/engg1245)\]); these index numbers for words in the regional languages correspond to the index numbers of the concepts in the reference Holle List/NBL. It is important to note that there is only one volume of the NBL; the content of the NBL is not repeated in the remaining volumes for the expressions/words in the regional language-varieties, but only the index numbers.

[^1]: See these Holle List publication series [on this page](https://openresearch-repository.anu.edu.au/search?spc.page=1&query=Holle%20Lists&scope=bbe2244b-212d-44b4-b33a-59048fd7e13f).

In the above two-parts publication setup, linguists, who are interested in the Dutch, English, and Indonesian/Malay translations of *a* given word in *a* given regional language, must manually match the index number of that regional word with the same index number in the reference Holle List. Let us use the data snippet in @fig-matching-master-and-regional as an example.

```{r}
#| label: fig-matching-master-and-regional
#| fig-cap: "Correspondence between index numbers of the regional list of Enggano and of the reference Holle List (or the New Basic List [NBL])."
#| fig-subcap: 
#|   - "the reference Holle List/NBL [@holleli1980]"
#|   - "Enggano regional list [@holle-list-barrier-islands]"
#| fig-cap-location: bottom
#| out-width: "80%"
#| layout-nrow: 2

knitr::include_graphics("img/matching-master-list.png")
knitr::include_graphics("img/matching-enggano-list.png")

```

To understand what the Enggano word “èbaka” (ID number 3) refers to in Dutch, English, and Indonesian/Malay, one must look up the ID number 3 in the NBL. In this case, “èbaka” in Enggano refers to ‘*gezicht, aangezicht*’ in Dutch, ‘face’ in English, and ‘*muka*, *wajah*’ in Indonesian/Malay. Alternatively, from the perspective of the NBL, linguists could have asked how a given concept is lexicalised in a given language. For example, the concept of ‘*lichaam*’ or ‘body’ in English (and ‘*badan, tubuh*’ in Indonesian) (ID number 1 in the NBL) can be lexicalised by two forms in Enggano, as shown by those given for the ID number 1 in the Enggano list, viz. “kărāhā” and “koedŏdŏkŏ”.

With such paper-based, separate setup between words in the regional languages and their translations, one could imagine the amount of manual back-and-forth procedure needed to link the words and their translations. The development of modern data science [@donoho2017] allows us to handle such a problem in a computational way. The Holle List setup can be conceived as disjointed relational data with common keys; these shared keys are the index numbers present in both data set (the NBL and the given regional list). Then, they can be computationally joined at scale once they are both in computer-readable format [see @wickham2023, Ch. 19, for the description of table-joining and its computational implementation in the R programming language].

In order to tackle the problem of manual matching, with a desiderata for computational matching between the NBL and the regional lists, the PDF file containing the NBL table [@holleli1980] has been digitalised. The NBL list is now available as a computer-readable, searchable and manipulable database [@rajeg2023]; this is also available online as a webpage at <https://engganolang.github.io/digitised-holle-list/>. The joining of the translations in the digitalised NBL data into the regional list data is via the matching keys, viz. the index numbers. This digitalised NBL (in a tab-separated plain-text file) has first been implemented in joining the (also digitalised) regional word list for Enggano with the corresponding Dutch, English, and Indonesian glosses in the master Holle List [@rajeg2023eno; @rajeg2025].

Continuing the Enggano research, I envisaged the computational matching between the NBL and all words from the remaining regional languages in the Holle List. To achieve this, the first step is to digitalise the other regional languages from the PDF files into plain texts. Since there are no less than 100 regional lists (comprising of ten volumes) in the Holle List, we need a way to scale-up the digitalisation process.

This paper highlights the use of cloud computing platform, that is “Google Colaboratory” (<https://colab.google/>) [@google2026], to handle the computational resources (such as the Central Processing Unit and Memory) to run large-scale digitalisation process of many PDF files into into plain-text file. The software that performs the remediation from PDF to plain text is the *Tesseract* O(ptical) C(haracter) R(ecognition) engine [@smith2007] (see @sec-data-source-processing for further details). Once the digitalisation output of the regional lists has been checked, edited for errors (cf. @sec-results) , and tagged to separate each language in the source PDF file, it is possible to computationally collate what was two-parts paper-borne publications into a digital cross-linguistic lexical database whereby the words in the regional languages are matched with their corresponding Dutch, English, and Indonesian/Malay glosses.

The future potentials of these large lexical data are diverse. It will open new possibilities for systematic computational historical linguistic analysis in finding relationship between languages [@lai2023]. The database can also be used to study diachronic changes of the same language, combining the older data set and (if available) the present-day, modern dataset [@krauße; @rajeg2024]. In the area of lexical semantics, the database could be used to investigate collexification patterns (i.e., cross-language polysemy) [@clics2020; @françois2008]. Last but not least, the database contributes to the preservation of Indonesian regional languages, especially the older varieties.

## Methodology {#sec-method}

### Data source acquisition {#sec-data-source-acquisition}

The PDF files for all eleven volumes of the Holle List series are available open access on the Open Research Repository of the Australian National University (ANU) library, under the [“ANU Asia-Pacific Linguistics/Pacific Linguistics Press” collection](https://openresearch-repository.anu.edu.au/collections/bbe2244b-212d-44b4-b33a-59048fd7e13f). The Holle List publications can be looked up using "Holle Lists" as the search term (see @fig-holle-list-search-output).

[![A snippet of the search results for the Holle List publications on the ANU Open Research Repository](img/holle-list-search-results.png){#fig-holle-list-search-output}](https://openresearch-repository.anu.edu.au/search?spc.page=1&query=Holle%20Lists&scope=bbe2244b-212d-44b4-b33a-59048fd7e13f)

The PDF files for every volume was downloaded and uploaded onto the Google Drive of the Holle List project so that they are accessible when processed in the Google Colab coding environment. This is explained next.

### Data processing {#sec-data-source-processing}

To use Google Colab, one only needs to sign up for a Google Account (if they have not had one). After signing-in to one’s Google Account, go to <https://colab.google/> and choose the New Notebook option. A computational Jupyter Notebook will be created and stored in the Google Drive folder. This Notebook runs Python programming language (see @fig-jupyter-notebook). All computations for the digitalisation happened on this online, cloud computer on Google Colab.

![A snippet of an interface of the Jupyter Notebook in Google Colab](img/google-collab-notebook-interface.png){#fig-jupyter-notebook}

The codes shown in @fig-jupyter-notebook are for installing relevant software in the remediation process from PDF into plain text. The *Tesseract OCR* engine (see the code `!sudo apt install tesseract-ocr`) as well as the Python package/module *pytesseract* [@hoffstaetter2024] were installed to allow access to *Tesseract* via Python. Before converting the PDF into plain text with the *pytesseract*, the PDF files need to be converted into images using the `pdf2image` module [@belval2024].

The next step is to load the necessary functionality from the installed modules for PDF-to-text conversion, including a function that allows accessing the downloaded PDFs stored on Google Drive (cf. @fig-holle-list-search-output). This is shown in @fig-module-load.

![Loading the relevant functions from the installed modules](img/google-colab-module-load.png){#fig-module-load}

After loading the relevant functions by executing codes in @fig-module-load, we need to write custom Python codes for the digitalisation processes. An example is shown in @fig-python-ocr for the processing of the regional Holle List vol. 5/1 for the Papuan and Austronesian languages in the Digul Area, Irian Jaya/West Papua, Indonesia [@stokhof1982].

![Custom Python codes for the digitalisation of the PDF into plain text](img/google-colab-digitalisation.png){#fig-python-ocr}

Codes in the upper code block/box in @fig-python-ocr deal with converting the PDF into image by providing the Google Drive path of the PDF. After that come the codes in the lower code block/box in @fig-python-ocr. They cover three aspects:

1.  Setting-up the parameters or configuration for the output format of the plain text. Details can be found at <https://tesseract-ocr.github.io/tessdoc/Command-Line-Usage.html>
2.  Creating the main processing iteration to convert the images into a single text file. This is shown from the code line containing `for i, image in enumerate(images):` up until the line stating `full_text += "\n\n"`.
3.  Saving the output into a plain text file; this file is stored on a Google Drive folder chosen by the user. The code line shown in @fig-python-ocr indicates that the output is saved with the file name `HolleList-Vol-5-1-Irian-Jaya.txt` under a folder for the Vol. 5/1, which is in turn inside the `hollelist` sub-folder in my main Google Drive folder (`MyDrive`) (see @fig-ocr-output).

![A Google Drive folder containing the plain-text (.txt) output of the OCR operation for the PDF of the Holle List vol. 5/1](img/digitalisation-output.png){#fig-ocr-output}

Note that writing the codes as presented in @fig-python-ocr does not necessarily mean that the codes are automatically executed/instructed to produce the output. To run the codes inside a given code block, hover the mouse in the top-left area of the code block until a white rightward arrow (with black background) appears (see the point of the blue arrow in @fig-executing-code), then click on that white arrow.

![The execution of the codes using the graphical user interface button or keyboard shortcut](img/google-colab-running-code.png){#fig-executing-code}

Alternatively, ensure the cursor is in the relevant code block and then use the keyboard shortcut `Ctrl+Enter` to execute the codes in that code block.

As mentioned in @sec-intro, the execution of these codes is not performed locally on our laptop but online on the cloud, using the Central Processing Unit (CPU) and the memory provided by the Google Colab. It is also important to note that the conversion processes from image files into plain texts for a given volume could take more than one hour. In this study, I did not take note on the processing times for digitalising each volume because the primary goal is not to assess the efficiency and processing times.

## Results {#sec-results}

In this section, I present two sets of results from a single volume, namely the Holle List vol. 5/1 [@stokhof1982] for Austronesian and Papuan languages in the Digul area, Irian Jaya (West Papua). They illustrate the contrast of the quality of the conversion output, depending on the nature of the input-characters in the source PDF file. These two sets represent two different languages in that volume, namely Numfor [@stokhof1982, 17] and Digul Mappi (spoken in the area between the Digul river and the Mappi river) [@stokhof1982, 133].

@fig-numfor-1 captures several words in Numfor in the PDF source file while @fig-numfor-2 shows their corresponding OCR conversion output in plain-text.

```{r}
#| label: fig-numfor
#| fig-cap: "Snippets of the PDF source for the Numfor list and its corresponding plain-text format after the image-to-text conversion"
#| fig-subcap: 
#|   - "the PDF source [@stokhof1982, 17]"
#|   - "the plain-text output"
#| fig-cap-location: bottom
#| out-width: "80%"
#| layout-nrow: 2
#| echo: hide

knitr::include_graphics("img/numfor-pdf.png")
knitr::include_graphics("img/numfor-txt.png")
```

The pair in @fig-numfor can now be contrasted with that for the Digul Mappi list in @fig-digulmappi.

```{r}
#| label: fig-digulmappi
#| fig-cap: "Snippets of the PDF source for the Digul Mappi list and its corresponding plain-text format after the image-to-text conversion"
#| fig-subcap: 
#|   - "the PDF source [@stokhof1982, 133]"
#|   - "the plain-text output"
#| fig-cap-location: bottom
#| out-width: "80%"
#| layout-nrow: 2
#| echo: hide

knitr::include_graphics("img/digul-mappi-pdf.png")
knitr::include_graphics("img/digul-mappi-txt.png")
```

## Discussion

-   ...

-   Computational OCR let us obtain results relatively quickly

    -   Pros: non-accented and unformatted (e.g., without underscore) Roman characters are generally well-represented in the OCR output. This means that the effort and time to re-type (or manually type) these well-recognised characters could be effectively reduced, with the focus is only scanning/checking.

    -   Cons: not all characters are recognised correctly (example: )

        -   opportunity: the editing phase of these unrecognised characters can be annotated, tracked and versioned for changes so that we can quantify which character(s) is consistently misrepresented [cf. @fomin2006, 84]

## Conclusion

We need to keep in mind that the regional language data represent the state of the language in the late 19th century and/or early 20th century. Other things to keep in mind is that there can be variation of orthography/spelling between investigators of different

## References
